<html>
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>IKEA Manuals at Work: 4D Grounding of Assembly Instructions on Internet Videos</title>
  
    <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">
  
    <link rel="stylesheet" href="./static/css/bulma.min.css">
    <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
    <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
    <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
    <link rel="stylesheet" href="./static/css/index.css">
    <link rel="icon" type="image/png" href="./assets/favicon.png">
  
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
    <script defer src="./static/js/fontawesome.all.min.js"></script>
    <script src="./static/js/bulma-carousel.min.js"></script>
    <script src="./static/js/bulma-slider.min.js"></script>
    <script src="./static/js/index.js"></script>
    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-V2CTB61RPJ"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-V2CTB61RPJ');
    </script>
</head>
<body>

<!-- Navigation Bar -->
<nav class="navbar">
  <ul>
    <li><a href="#abstract">Abstract</a></li>
    <li><a href="#dataset-overview">Dataset Overview</a></li>
    <li><a href="#furniture-models">Furniture Models</a></li>
    <li><a href="#annotation">Annotation</a></li>
    <!-- <li><a href="#environments"><span class="new-label-navbar">NEW</span> Environments </a></li> -->
    <li><a href="#environments"> Environments </a></li>
    <li><a href="#data-collection">Data Collection and Annotation</a></li>
    <!-- <li><a href="#pose-refinement"><span class="new-label-navbar">NEW</span> Pose Refinement </a></li> -->
     <li><a href="#pose-refinement"> Pose Refinement </a></li>
    <!-- <li><a href="#applications"><span class="new-label-navbar">NEW</span> Applications</a></li> -->
     <li><a href="#applications"> Applications</a></li>
    <!-- <li><a href="#challenges"><span class="new-label-navbar">NEW</span> Real-World Challenges</a></li> -->
    <li><a href="#challenges"> Real-World Challenges</a></li>
  </ul>
</nav>

  
<section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">IKEA Manuals at Work: 4D Grounding of Assembly Instructions on Internet Videos</h1>
            <div class="is-size-5 publication-authors">
              <span class="author-block">
                <a href="http://yunongliu.com/">Yunong Liu</a><sup>1</sup></span>,
    
              <span class="author-block">
                <a href="https://ceyzaguirre4.github.io">Cristobal Eyzaguirre</a><sup>1</sup></span>,
              <span class="author-block">
                <a href="https://limanling.github.io">Manling Li</a><sup>1</sup></span>,
                <span class="author-block">
                  <a href="author3_website">Shubh Khanna</a><sup>1</sup></span>,
            </div>

            <div class="is-size-5 publication-authors">
              <span class="author-block">
                <a href="https://www.niebles.net">Juan Carlos Niebles</a><sup>1</sup></span>,
              <span class="author-block">
                <a href="author7_website">Vineeth Ravi</a><sup>2</sup></span>,
              <span class="author-block">
                <a href="author8_website">Saumitra Mishra</a><sup>2</sup></span>,
              <span class="author-block">
                <a href="http://weiyuliu.com">Weiyu Liu*</a><sup>1</sup></span>,
              <span class="author-block">
                <a href="https://jiajunwu.com">Jiajun Wu*</a><sup>1</sup></span>
            </div>
            (*Equal advising)
  
            <div class="is-size-5 publication-authors">
              <span class="author-block"><sup>1</sup>Stanford University</span>
              <span class="author-block"><sup>2</sup>J.P. Morgan AI Research</span>
            </div>

            <div class="column has-text-centered">
              <div class="publication-links">
                <!-- PDF Link. -->
                <span class="link-block">
                  <a href="path_to_your_paper.pdf" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                    </span>
                    <span>Paper (Coming Soon)</span>
                  </a>
                </span>
                <!-- Code Link. -->
                <span class="link-block">
                  <a href="https://github.com/yunongLiu1/IKEA-Manuals-at-Work" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>
                <!-- Dataset Link. -->
                <span class="link-block">
                  <a href="https://github.com/yunongLiu1/IKEA-Manuals-at-Work" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="far fa-images"></i>
                    </span>
                    <span>Dataset</span>
                  </a>
                </span>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
</section>

<!-- Abstract -->

<div class="container is-max-desktop">

  
<section class="hero teaser">
    <div class="container is-max-desktop">
      <div class="hero-body">
        <!-- Add a GIF -->
        <p>
          The IKEA Video Manuals dataset is <strong>the first dataset to provide 4D grounding of assembly instructions on Internet videos</strong>, offering high-quality, spatial-temporal alignments between assembly instructions, 3D models, and real-world internet videos.</br>
        <figure>
          <img src="./assets/teaser.gif" alt="Teaser">
           <!-- <img src="./assets/teaser-ezgif.com-crop.gif" alt="Teaser">  -->
          <!-- <figcaption>Fig. 1: One Example of the IKEA Video Manuals dataset.</figcaption> -->
      </div>
    </div>
</section>
<section id="abstract" class="section">
    
  <h2 class="title is-3">Abstract</h2>
  <p>
    Shape assembly is a ubiquitous task in daily life, integral for constructing complex 3D structures like IKEA furniture. While significant progress has been made in developing autonomous agents for shape assembly, existing datasets have not yet tackled the 4D grounding of assembly instructions in videos, essential for a holistic understanding of assembly in 3D space over time. We introduce IKEA Video Manuals, a dataset that features 3D models of furniture parts, instructional manuals, assembly videos from the Internet, and most importantly, annotations of dense spatio-temporal alignments between these data modalities. To demonstrate the utility of IKEA Video Manuals, we present five applications essential for shape assembly: assembly plan generation, part-conditioned segmentation, part-conditioned pose estimation, video object segmentation, and furniture assembly based on instructional video manuals. For each application, we provide evaluation metrics and baseline methods. Through experiments on our annotated data, we highlight many challenges in grounding assembly instructions in videos to improve shape assembly, including handling occlusions, varying viewpoints, and extended assembly sequences.</p>
</section>

<!-- <section class="section">
    <div class="container is-max-desktop">
      <h2 class="title is-3">Video</h2>
      <div class="publication-video">
        <iframe src="./assets/ikea-video-figures-widened_video.m4v" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
      </div>
    </div>
</section> -->

<section class="section">
    <div class="container is-max-desktop">
      <h2 class="title is-3">Dataset Overview</h2>
      Different instruction forms provide different temporal decomposition of the process. Instruction manuals often provide high-level decomposition, while how-to videos demonstrate more detailed steps of each part assembly. Our dataset aligns each step from the instruction manual with a sequence of substep, in which sub-assemblies are formed (a,b). These substeps are further mapped to segments of the how-to videos, which provide a frame-by-frame demonstration of the assembly. 
      Our dataset further provides spatial details of the whole assembly process in 3D (d) observed from the instruction manuals and videos. These details are provided in the form of 6-DoF pose trajectories of the furniture parts. Specifically, for each video frame, the parts being assembled are annotated with a 2D image mask. The pose of each object part in the camera frame is provided, while the relative poses between parts that are being assembled are detailed. With the additional camera intrinsics we provide, the 3D parts can also be projected into 2D image space and aligned with their corresponding 2D mask.   

      <figure>
        <img src="./assets/Overview.jpg" alt="Dataset Overview">
        <!-- <figcaption>Fig. 1: Dataset overview showing the alignment of 3D models, instruction manuals, and video frames.</figcaption> -->
      </figure>
      </div>
</section>

<!-- <section class="section">
    <div class="container is-max-desktop">
      <h2 class="title is-3">Key Features</h2>
      <ul>
        <li>Multiple instruction forms for assembly, including high-level assembly tree, instruction manuals, and assembly videos</li>
        <li>Temporal alignment of instruction and assembly process at different granularities</li>
        <li>Spatial alignment of instruction and assembly process in 3D</li>
        <li>Diversity in assembly scenarios, encompassing various furniture types, designs, and processes</li>
        <li>Complexity in real-world videos, capturing challenges such as camera changes, occlusions, and diverse backgrounds</li>
      </ul>
    </div>
</section> -->





<section id="furniture-models" class="section">
  <div class="container is-max-desktop">
    <h2 class="title is-3">Furniture Models</h2>
    <p>The IKEA Video Manuals dataset includes 36 furniture models from 6 categories:</p>
    <ul style="list-style-type: disc;">
      <li>Chairs (20 types)</li>
      <li>Tables (8 types)</li>
      <li>Benches (3 types)</li>
      <li>Desks (1 type)</li>
      <li>Shelves (1 type)</li>
      <li>Misc (3 type)</li>
    </ul>
    <div class="image-container">
      <figure>
        <img src="./assets/allFurnitures.jpg" alt="All Furniture Models">
        <!-- <figcaption>Fig. 2: All furniture models included in the IKEA Video Manuals dataset.</figcaption> -->
      </figure>
    </div>
  </div>
</section>

<!-- \begin{figure}[t]
    \centering
    \includegraphics[width=\textwidth]{Images/oneFrameExample_2.pdf}
    \caption{Example of annotations provided for a single frame in the IKEA Video Manuals dataset, including furniture-level, video-level, assembly step-level, frame-level, and manual-level information.}
    \label{fig:oneFrameExample}
\end{figure} -->

<section id="annotation" class="section">
  <div class="container is-max-desktop">
    <h2 class="title is-3">Annotation</h2>
    <p>For each video frame, we provide detailed annotations at five levels:</p>
    <div class="container">
      <style>
        .info-container {
        display: flex;
        flex-wrap: wrap;
        justify-content: space-between;
          }
        .info-section {
        width: 48%; /* Adjusted width to make sections wider */
        margin-bottom: 20px;
        padding: 20px;
        border: 1px solid #ccc;
        border-radius: 5px;
          }
        .info-section h3 {
        margin-bottom: 10px;
          }
        .info-section p {
        margin-bottom: 5px;
          }
        .image-section {
        margin-top: 20px;
          }
        .image-section img {
        max-width: 100%;
        height: auto;
        margin-bottom: 10px;
          }
        .frame-level-info {
        width: 100%; /* Added width to make the section full-width */
          }
        .frame-level-images {
        display: flex; /* Added flex display to arrange images horizontally */
        justify-content: space-between;
          }
        .frame-level-images img {
        width: 30%; /* Adjusted width to make images smaller */
          }
        .assembly-manual-info {
        display: flex;
        justify-content: space-between;
        width: 100%;
          }
        .assembly-manual-info .info-section {
        width: 48%;
          }
        .manual-level-info {
        display: flex; /* Added flex display to arrange text and image side by side */
        align-items: flex-start;
          }
        .manual-level-text {
        flex: 1; /* Added flex property to make the text section flexible */
        margin-right: 20px;
          }
        .manual-level-image {
        flex: 1; /* Added flex property to make the image section flexible */
          }
      </style>
      <div class="info-container">
        <div class="info-section">
          <h3><strong>Furniture Level Info</strong></h3>
          <p>Category: Bench</p>
          <p>Name: applaro</p>
          <p>Furniture IDs: ['90205182']</p>
          <p>Variants: []</p>
          <p>Furniture URLs: ['https://www.ikea.com/.../']</p>
          <p>Furniture Main Image URL: https://www.ikea....jpg</p>
        </div>
        <div class="info-section">
          <h3><strong>Video Level Info</strong></h3>
          <p>Video URL: https://www.youtube.com/...</p>
          <p>Other Video URLs for the Same Furniture: </p>
          <p>Title: IKEA assembly instructions, APPLARO Bench</p>
          <p>Duration: 155</p>
          <p>Is_indoor: indoor</p>
        </div>
        <div class="assembly-manual-info">
          <div class="info-section">
            <h3><strong>Assembly Step Info</strong></h3>
            <p>Step ID: 1</p>
            <p>Step Start: 47.0</p>
            <p>Step End: 62.1</p>
            <p>Substep ID: 3</p>
            <p>Substep Start: 62.04</p>
            <p>Substep End: 62.1</p>
          </div>
          <div class="info-section manual-level-info">
            <div class="manual-level-text">
              <h3><strong>Manual Level Info</strong></h3>
              <p>Manual Step ID: 1</p>
              <p>Manual URLs: ['https://www.ikea.com/...=4.pdf']</p>
              <p>Manual ID: AA-601524-4</p>
              <p>Manual Parts: ['0,1,2', '3']</p>
              <p>Manual Connections: [['0,1,2', '3']]</p>
              <p>PDF Page: 4</p>
            </div>
            <div class="manual-level-image">
              <img src="./assets/manual_mask.png" alt="Manual + Masks">
            </div>
          </div>
        </div>
        <div class="info-section frame-level-info">
          <h3><strong>Frame Level Info</strong></h3>
          <p>Frame Time: 52.82</p>
          <p>Number of Camera Changes: 1</p>
          <p>Frame Parts: ['0,2', '1', '3']</p>
          <p>Frame ID: 1584</p>
          <p>Is Keyframe: False</p>
          <p>Is Frame Before Keyframe: False</p>
          <div class="frame-level-images">
            <img src="./assets/frame_img.png" alt="Frame Image">
            <img src="./assets/Mask.png" alt="Masks">
            <img src="./assets/pose.png" alt="Object Poses">
          </div>
        </div>
      </div>
    </div>
  </div>
</section>
<section id="environments" class="section">
    <div class="container is-max-desktop">
      <h2 class="title is-3">Environment (98 Videos)</h2>
      <!-- <span class="new-label">NEW !</span> -->

      <video controls>
        <source src="./assets/dataset_overview.mp4" type="video/mp4">
        Your browser does not support the video tag.
    </div>

</section>
<section id="data-collection" class="section">
    <div class="container is-max-desktop">
      <h2 class="title is-3">Data Collection and Annotation</h2>
      <p>The IKEA Video Manuals dataset is built on top of the IKEA-Manual dataset and the IAW dataset. It collects 36 segmented 3D furniture models from the IKEA-Manual dataset and 98 associated assembly videos from the IAW dataset.</p> 
      <!-- <figure>
        <img src="path_to_your_data_collection_figure" alt="Data Collection">
        <figcaption>Fig. 3: Data collection process combining 3D models, instruction manuals, and assembly videos.</figcaption>
      </figure> -->
      <!-- <p>The dataset provides extensive annotations, including:</p>
      <ul>
        <li>Fine-grained temporal segmentation of videos based on the construction of each sub-assembly</li>
        <li>2D image segmentation masks for 3D parts in sampled frames</li>
        <li>3D poses of furniture parts in video frames</li>
        <li>Camera parameter estimation for each video segment</li>
        <li>Hierarchical assembly trees representing the assembly process</li>
      </ul> -->
      <div class="medium-image">
      <figure>
        <img src="./assets/pipeline.jpg" alt="Annotation Pipeline">
        <figcaption>Fig. 4: Annotation pipeline for the IKEA Video Manuals dataset.</figcaption>
      </figure>
    </div>
    </div>
</section>

<section id="pose-refinement" class="section">
  <div class="container is-max-desktop">
    <h2 class="title is-3">Pose Refinement</h2>
    <!-- <span class="new-label">NEW !</span> -->
    <div class="content">
      <p>
        Our pose refinement processimproves the accuracy of 3D part poses in assembly videos. This process is crucial for ensuring physically valid assembly sequences and accurate 3D reconstructions.
      </p>
      <ol>
        <li><strong>Initial Estimation:</strong> We start with the Perspective-n-Point (PnP) algorithm to estimate initial poses. While this provides a good 2D overlay, it often results in inaccurate 3D poses.</li>
        <li><strong>Issue Identification:</strong> By viewing the scene from different angles, particularly side views, we reveal incorrect spatial relationships between parts that aren't apparent from the camera's perspective.</li>
        <li><strong>Refinement Process:</strong> We've developed an interactive interface that allows annotators to:
          <ul>
            <li>Control the virtual camera using axis-aligned controls</li>
            <li>View the 3D scene from different orthographic perspectives</li>
            <li>Refine part poses by rotating and translating them in 3D space</li>
            <li>Compare the real-time 3D view with corresponding video frames</li>
          </ul>
        </li>
        <li><strong>Relative Pose Accuracy:</strong> To improve the accuracy of relative poses, parts that appear together in a video frame are annotated simultaneously, with a visualization of their 3D locations.</li>
        <li><strong>Temporal Smoothness:</strong> We initialize part poses with poses from the previous frame to improve the temporal smoothness of part trajectories.</li>
      </ol>
      
    </div>
    <figure class="image">
      <img src="./assets/refine_example2.png" alt="Pose Refinement Process">

    </figure>
    <p>
      This refinement process is essential for constructing physically valid assembly sequences and ensuring the final 3D model accurately matches the real-world object. It addresses key challenges in 3D pose estimation from 2D internet videos, particularly in complex assembly scenarios with multiple interacting parts.
    </p>

    <h3 class="title is-4">More Examples</h3>
    <figure>
      <img src="./assets/refine_example.gif" alt="Pose Refinement">

    </figure>

    <p>
      This animation shows the assembly process in 4D from the front and side views before and after pose refinement. The relative poses between objects are significantly improved after refinement, leading to a more accurate 3D reconstruction of the final assembly.  This is particularly important for complex furniture items with multiple interacting parts, where small errors can compound into significant misalignments in the final assembly.
    </p>
  </div>
</section>

<section id="applications" class="section">
  <div class="container is-max-desktop">
    <h2 class="title is-3">Applications</h2>
    <p>The IKEA Video Manuals dataset showcases its versatility and practical relevance through four fundamental furniture analysis tasks:</p>
    <ol>
      <li>
        <strong>Assembly Plan Generation</strong>
        <p>This task focuses on predicting a hierarchical assembly plan by analyzing a sequence of video frames that depict the furniture assembly process. The dataset offers physically realistic assembly plans extracted from Internet videos, providing a more detailed and diverse set of assembly steps compared to plans derived solely from instruction manuals.</p>
        <div class="image-container">
          <figure>
            <img src="./assets/assembly_plan_generation.png" alt="Assembly Plan Generation">
            <!-- <figcaption>Fig. 6: Assembly plan generation results on the IKEA Video Manuals dataset.</figcaption> -->
          </figure>
        </div>
      </li>
      <li>
        <strong>Part-Conditioned Segmentation</strong>
        <p>The objective of part-conditioned segmentation is to generate pixel-wise segmentation masks for furniture sub-assemblies within the assembly process. The diverse videos in the dataset enable the evaluation of part segmentation methods in real-world scenarios. The results emphasize the challenges posed by occlusions, complex backgrounds, and textureless 3D shapes when detecting object parts in Internet videos.</p>
        <figure>
          <img src="./assets/part_segmentation.png" alt="Part-Conditioned Segmentation">
          <!-- <figcaption>Fig. 7: Part-conditioned segmentation results on the IKEA Video Manuals dataset.</figcaption> -->
        </figure>
      </li>
      <li>
        <strong>Part-Conditioned Pose Estimation</strong>
        <p>Part-conditioned pose estimation aims to predict the 6D pose of a furniture sub-assembly in a video frame. Accurate estimation of 3D poses of furniture parts from each video frame is crucial for developing a grounded understanding of the assembly process.</p>
        <figure>
          <img src="./assets/part_pose_estimation.png" alt="Part-Conditioned Pose Estimation">
          <!-- <figcaption>Fig. 8: Part-conditioned pose estimation results on the IKEA Video Manuals dataset.</figcaption> -->
        </figure>
      </li>
      <li>
        <strong>Mask Tracking</strong>
        <!-- <span class="new-label">NEW !</span> -->

        <p>We evaluated two state-of-the-art mask tracking models, SAM2 and Cutie, on our dataset. Our analysis reveals significant challenges that these models face in real-world assembly scenarios.</p>
        
        <table class="table is-bordered is-striped is-narrow is-hoverable is-fullwidth">
          <thead>
            <tr>
              <th>Dataset</th>
              <th>SAM2 (Hiera-L) J&F</th>
              <th>Cutie-base J&F</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td>Our Dataset</td>
              <td>0.736</td>
              <td>0.547</td>
            </tr>
            <tr>
              <td>MOSE</td>
              <td>0.772</td>
              <td>0.699</td>
            </tr>
            <tr>
              <td>DAVIS 2017 val</td>
              <td>0.916</td>
              <td>0.879</td>
            </tr>
            <tr>
              <td>SA-V val</td>
              <td>0.756</td>
              <td>0.607</td>
            </tr>
            <tr>
              <td>YouTubeVOS 2019 val</td>
              <td>0.891</td>
              <td>0.870</td>
            </tr>
          </tbody>
        </table>
    
        <!-- <ul>
          <li>Both models show performance drops on our dataset compared to existing benchmarks.</li>
          <li>Our dataset presents unique challenges not captured in current benchmarks, including MOSE and SA-V, which were designed to be more difficult than standard datasets.</li>
          <li>The substantial performance gap highlights the potential of our dataset to drive advancements in video object segmentation research.</li>
        </ul> -->
      
        <p>Error Analysis:</p>
        <ul>
          <li><strong>Camera Changes:</strong> Both models struggle with abrupt camera movements, often losing track of the object of interest.</li>
          <li><strong>Similar Appearances:</strong> In assembly scenarios with multiple similar parts, the models often confuse different parts, leading to tracking errors.</li>
          <!-- <li><strong>Occlusions:</strong> The models have difficulty re-identifying objects after they've been occluded, especially in cluttered assembly environments.</li>
          <li><strong>Small Objects:</strong> Tracking performance degrades significantly for smaller parts, which are common in furniture assembly.</li>
          <li><strong>Long-term Consistency:</strong> Both models struggle to maintain consistent tracking over extended periods, which is crucial for complete assembly sequences.</li> -->
        </ul>
      
        <div class="columns is-multiline">
          <div class="column is-one-third">
            <figure class="image">
              <img src="./assets/gt_cam_change.gif" alt="Ground Truth Camera Changes">
              <figcaption>
                <strong>Ground Truth: Camera Changes</strong>
              </figcaption>
            </figure>
          </div>
          <div class="column is-one-third">
            <figure class="image">
              <img src="./assets/cutie_cam_change.gif" alt="Cutie Camera Changes">
              <figcaption>
                <strong>Cuties: Camera Changes</strong> Cuties successfully tracks some portion of the furniture piece after camera changes, but loses track of the rest.
              </figcaption>
            </figure>
          </div>
          <div class="column is-one-third">
            <figure class="image">
              <img src="./assets/sam2_cam_change.gif" alt="SAM2 Camera Changes">
              <figcaption>
                <strong>SAM2: Camera Changes</strong> The model loses track after abrupt camera movement.
              </figcaption>
            </figure>
          </div>
          <div class="column is-one-third">
            <figure class="image">
              <img src="./assets/gt_similar_appearance.gif" alt="Ground Truth Similar Appearance">
              <figcaption>
                <strong>Ground Truth: Similar Appearance</strong> 
              </figcaption>
            </figure>
          </div>
          <div class="column is-one-third">
            <figure class="image">
              <img src="./assets/cutie_similar_appearance.gif" alt="Cutie Similar Appearance">
              <figcaption>
                <strong>Cuties: Similar Appearance</strong> The model fail to track the pad at top of the chair.
              </figcaption>
            </figure>
          </div>
          <div class="column is-one-third">
            <figure class="image">
              <img src="./assets/sam2_similar_appearance.gif" alt="SAM2 Similar Appearance">
              <figcaption>
                <strong>SAM2: Similar Appearance</strong> SAM2 fails to track some parts of the chair.
              </figcaption>
            </figure>
          </div>
        </div>
      </li>
      <li>
        <strong>Shape Assembly with Instruction Videos</strong>
        <p>Given a set of 3D parts and an instruction video, shape assembly with instruction videos aims to determine the 6D poses of the 3D parts to assemble them into a complete piece of furniture. The proposed modular video-based shape assembly pipeline incorporates keyframe detection, assembled part recognition, pose estimation, and iterative assembly. </p> 
  </div>
</section>
<section id="challenges" class="section">
  <div class="container is-max-desktop">
    <h2 class="title is-3">Challenges in Real-World Assembly Videos</h2>
    <!-- <span class="new-label">NEW !</span> -->
    <div class="columns is-multiline">
      <div class="column is-half">
        <figure class="image">
          <img src="./assets/camera_changes.gif" alt="Camera Changes">
          <figcaption>
            <strong>Camera Changes:</strong> Camera changes are common in real-world assembly videos, introducing challenges for tracking and camera calibration.
          </figcaption>
        </figure>
      </div>
      <div class="column is-half">
        <figure class="image">
          <img src="./assets/heavy_occlusions.gif" alt="Heavy Occlusion">
          <figcaption>
            <strong>Heavy Occlusion:</strong> Occlusions are prevalent in assembly scenarios, especially when multiple parts are being assembled simultaneously, or when the camera is positioned close to the assembly area.
          </figcaption>
        </figure>
      </div>
      <div class="column is-half">
        <figure class="image">
          <img src="./assets/ambiguities.gif" alt="Construction Deconstruction">
          <figcaption>
            <strong>Construction Deconstruction:</strong> In real-world assembly scenarios, which is different from controlled environments, construction and deconstruction can be ambiguous. In the example shown, the user first assembles a part and then disassembles at 8s.
          </figcaption>
        </figure>
      </div>
      <div class="column is-half">
        <figure class="image">
          <img src="./assets/diverse_environment.gif" alt="Diverse Environment">
          <figcaption>
            <strong>Diverse Environment:</strong> Our dataset includes diverse assembly scenarios, such as multi-person assembly and outdoor assembly, which introduce additional challenges for tracking and pose estimation.
          </figcaption>
        </figure>
      </div>
    </div>
  </div>
</section>


<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@inproceedings{
      liu2024ikea,
      title={{IKEA} Manuals at Work: 4D Grounding of Assembly Instructions on Internet Videos},
      author={Yunong Liu and Cristobal Eyzaguirre and Manling Li and Shubh Khanna and Juan Carlos Niebles and Vineeth Ravi and Saumitra Mishra and Weiyu Liu and Jiajun Wu},
      booktitle={The Thirty-eight Conference on Neural Information Processing Systems Datasets and Benchmarks Track},
      year={2024},
      url={https://openreview.net/forum?id=EXwf5iE98P}
      }</code></pre>
  </div>
</section>

<footer class="footer">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
          Commons Attribution-ShareAlike 4.0 International License</a>.
        </p>
        <p>
          Website template borrowed from here. <a href="https://nerfies.github.io/"> Nerfies</a> 
        </p>
        <div id="globe-container" style="width: 200px; height: 200px;">
          <script type="text/javascript" id="clustrmaps" src="//clustrmaps.com/map_v2.js?d=aRVaiimtOlw90sDIsY5DzdKUoYuWi10wpnWUQE0Us3s&cl=ffffff&w=a"></script>
      </div>
      </div>
    </div>
  </div>
</footer>

  
</body>
</html>
